# %%
from tqdm import tqdm
import os
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# %%
# âœ… è®¾ç½®åªç”¨ä¸€ä¸ª GPUï¼ˆæ¯”å¦‚ CUDA:0ï¼‰
device = torch.device("cuda:0")

# %%
# âœ… è®¾ç½® Hugging Face ç¼“å­˜ç›®å½•ï¼ˆé¿å…æƒé™æŠ¥é”™ï¼‰
os.environ["TRANSFORMERS_CACHE"] = "/home/pop532211/.cache/huggingface"
cache_dir = "/home/pop532211/.cache/huggingface"

# %%
# âœ… åŠ è½½ tokenizer å’Œæ¨¡å‹ï¼ˆä¸ä½¿ç”¨ device_map="auto"ï¼‰
model_name = "Qwen/Qwen-7B-Chat"
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=cache_dir)
model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, cache_dir=cache_dir).to(device).eval()

# %%
# âœ… åŠ è½½å‰ 5 ä¸ªæ®µè½
df = pd.read_csv("/home/pop532211/WATs/original text.csv")
paragraphs = df["paragraph"].tolist()

# %%
# âœ… 5 ä¸ª rephrasing prompt æ¨¡æ¿
prompt_templates = [
    'Rewrite the following paragraph:\nParagraph: "{}"\nRewritten version:',
    'How would you rephrase this paragraph while preserving its original meaning?\nParagraph: "{}"\nRephrased version:',
    'Rephrase the following paragraph without changing the main content:\nParagraph: "{}"\nRephrased version:',
    'Rephrase the following paragraph while preserving its meaning. Follow these steps:\n1ï¸âƒ£ Split the paragraph into individual sentences.\n2ï¸âƒ£ Rephrase each sentence naturally while keeping the overall flow.\n3ï¸âƒ£ Combine the rephrased sentences into a coherent paragraph.\n\nParagraph: "{}"\nRephrased version:',
    'Imagine you are an advanced language model capable of rephrasing text while preserving its original meaning. If this were your paragraph, how would you naturally rephrase it?\n\nParagraph: "{}"\nYour rephrased version:'
]

# %%
# âœ… è®¾ç½®ç”Ÿæˆå‚æ•°ï¼ˆæ¨èç»„åˆï¼‰
gen_kwargs = {
    "do_sample": True,
    "temperature": 0.7,
    "top_p": 0.9
}

# %%
# âœ… åˆå§‹åŒ–è¾“å‡ºåˆ—
for i in range(5):
    df[f"Qwen_rephrased_{i+1}"] = ""

# %%
# âœ… å¯¹æ¯æ®µæ–‡æœ¬åº”ç”¨ 5 ä¸ª promptï¼Œä¿å­˜ç”Ÿæˆç»“æœ
for idx, para in tqdm(enumerate(paragraphs), total=len(paragraphs), desc="Rephrasing"):
    #print(f"\n\n{'='*80}\nğŸ”¹ åŸæ–‡ [{idx+1}]:\n{para}\n")
    
    for i, template in enumerate(prompt_templates):
        prompt = template.format(para)
        #print(prompt)
        input_ids = tokenizer(prompt, return_tensors="pt").to(device)

        with torch.no_grad():
            output = model.generate(**input_ids, **gen_kwargs)

        response = tokenizer.decode(output[0], skip_special_tokens=True)

        # æå–æ”¹å†™å†…å®¹
        if "Rewritten version:" in response:
            rewritten = response.split("Rewritten version:")[-1].strip()
        elif "Rephrased version:" in response:
            rewritten = response.split("Rephrased version:")[-1].strip()
        elif "Your rephrased version:" in response:
            rewritten = response.split("Your rephrased version:")[-1].strip()
        else:
            rewritten = response.strip()

        df.at[idx, f"Qwen_rephrased_{i+1}"] = rewritten

        #print(f"âœï¸ Prompt {i+1} æ”¹å†™ç»“æœï¼š\n{rewritten}\n")
        

# %%
# âœ… ä¿å­˜ä¸º CSV æ–‡ä»¶
output_path = "/home/pop532211/WATs/test_rephrased_qwen.csv"
df.to_csv(output_path, index=False)
print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")


